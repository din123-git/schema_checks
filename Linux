Here's a Linux script that reads the CSV file, checks for `is_active` = `true`, performs BigQuery snapshot and data copy, and updates the CSV file:

```
bash
#!/bin/bash

# Set variables
CSV_FILE="path/to/your/file.csv"
PROJECT_ID="your-project-id"
GCP_REGION="your-region"  # e.g., "US"
TIMESTAMP=$(date +"%Y%m%d%H%M%S")

# Check if CSV file exists
if [ ! -f "$CSV_FILE" ]; then
  echo "Error: CSV file not found."
  exit 1
fi

# Check if gcloud CLI is configured
if ! gcloud auth list 2>/dev/null | grep -q "ACTIVE"; then
  echo "Error: gcloud CLI not configured. Run 'gcloud auth login' and 'gcloud config set project $PROJECT_ID'"
  exit 1
fi

# Loop through CSV file
while IFS=, read -r source_project source_dataset source_table target_project target_dataset target_table is_active; do
  if [ "$is_active" = "true" ]; then
    # Create snapshot
    snapshot_name="${target_table}_${TIMESTAMP}"
    gcloud bq snapshots create "$snapshot_name" \
      --project "$target_project" \
      --dataset "$target_dataset" \
      --table "$target_table" \
      --expiration 3600s  # 1 hour expiration

    # Copy data from source to target
    gcloud bq cp \
      --project "$source_project" \
      --dataset "$source_dataset" \
      --table "$source_table" \
      --target-project "$target_project" \
      --target-dataset "$target_dataset" \
      --target-table "$target_table"

    # Update CSV file
    sed -i "/^$source_project,$source_dataset,$source_table,$target_project,$target_dataset,$target_table,/s/true/false/" "$CSV_FILE"
    echo "Processed: $source_project.$source_dataset.$source_table -> $target_project.$target_dataset.$target_table"
  fi
done < <(tail -n +2 "$CSV_FILE")  # Skip header row

echo "Script completed successfully."
```

*Prerequisites:*

1. Install `gcloud` CLI and configure authentication.
2. Replace `path/to/your/file.csv` with the actual CSV file path.
3. Set `PROJECT_ID` and `GCP_REGION` variables accordingly.
4. Ensure the CSV file has the exact column names and format specified.

*Exception Handling:*

1. Checks for CSV file existence.
2. Verifies `gcloud` CLI configuration.
3. Handles errors during snapshot creation and data copy.

*Notes:*

1. The script uses `gcloud` CLI for BigQuery operations.
2. Snapshot expiration is set to 1 hour (3600 seconds).
3. The script updates the CSV file by replacing `true` with `false` for processed rows.
4. The `sed` command assumes the CSV file has no trailing commas.

Test the script in a non-production environment before running it on your actual data.
